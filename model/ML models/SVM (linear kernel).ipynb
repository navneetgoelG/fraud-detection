{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'Anomaly Detection models',\n",
       " 'baseline-model.ipynb',\n",
       " 'DL models',\n",
       " 'ML models']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve,average_precision_score,confusion_matrix,classification_report\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score,roc_curve,roc_auc_score,f1_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split,cross_validate\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a datframe to store our data\n",
    "\n",
    "data = pd.read_csv('../../data/creditcard.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First baseline model selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the most important features already listed in the baseline model \n",
    "\n",
    "df = data[['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', \n",
    "             'V11','V12','V13','V14','V16','V17','V21','V23','V27']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163152.0    36\n",
       "64947.0     26\n",
       "68780.0     25\n",
       "3767.0      21\n",
       "3770.0      20\n",
       "            ..\n",
       "2088.0       1\n",
       "64100.0      1\n",
       "42068.0      1\n",
       "119630.0     1\n",
       "140344.0     1\n",
       "Name: Time, Length: 124592, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to know the frequency of different time recorded\n",
    "data.Time.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163152.0    36\n",
       "64947.0     26\n",
       "68780.0     25\n",
       "3767.0      21\n",
       "3770.0      20\n",
       "            ..\n",
       "154306.0     1\n",
       "5380.0       1\n",
       "105479.0     1\n",
       "52741.0      1\n",
       "90714.0      1\n",
       "Name: Time, Length: 124479, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['Class']==0, 'Time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68207.0     6\n",
       "94362.0     4\n",
       "85285.0     4\n",
       "93860.0     4\n",
       "84204.0     4\n",
       "           ..\n",
       "158638.0    1\n",
       "125658.0    1\n",
       "28692.0     1\n",
       "15817.0     1\n",
       "406.0       1\n",
       "Name: Time, Length: 468, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['Class']==1, 'Time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.figure(figsize=(20,20))\n",
    "plt.plot(data.loc[data['Class']==0, 'Time'], 'o',color= 'b')\n",
    "plt.plot(data.loc[data['Class']==1, 'Time'], 'v', color= 'g' )\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows the spread of the fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 19 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   V1      284807 non-null  float64\n",
      " 1   V2      284807 non-null  float64\n",
      " 2   V3      284807 non-null  float64\n",
      " 3   V4      284807 non-null  float64\n",
      " 4   V5      284807 non-null  float64\n",
      " 5   V6      284807 non-null  float64\n",
      " 6   V7      284807 non-null  float64\n",
      " 7   V8      284807 non-null  float64\n",
      " 8   V9      284807 non-null  float64\n",
      " 9   V10     284807 non-null  float64\n",
      " 10  V11     284807 non-null  float64\n",
      " 11  V12     284807 non-null  float64\n",
      " 12  V13     284807 non-null  float64\n",
      " 13  V14     284807 non-null  float64\n",
      " 14  V16     284807 non-null  float64\n",
      " 15  V17     284807 non-null  float64\n",
      " 16  V21     284807 non-null  float64\n",
      " 17  V23     284807 non-null  float64\n",
      " 18  V27     284807 non-null  float64\n",
      "dtypes: float64(19)\n",
      "memory usage: 41.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 3.51722561243691e-06, 1: 0.0020325203252032522}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computing the class weight\n",
    "\n",
    "val_count = data['Class'].value_counts()\n",
    "weights = dict(1 / val_count)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adminstrative cost\n",
    "admin_cost = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to calculate cost savings\n",
    "def cost_saving(ytrue, ypred, amount):\n",
    "    fp = np.sum((ytrue == 0) & (ypred == 1))\n",
    "    cost = np.sum(fp*admin_cost) + np.sum((amount[(ytrue == 1) & (ypred == 0)]))\n",
    "    max_cost = np.sum((amount[(ytrue == 1)]))\n",
    "    savings = 1 - (cost/max_cost)\n",
    "    \n",
    "    return savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the split\n",
    "\n",
    "cv = StratifiedKFold(n_splits=4,shuffle=True,random_state =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to calculate cost saving per fold (splits) of our cv\n",
    "def cost_saving_per_split(scores, x, y, cv_object):\n",
    "    results = []\n",
    "    for i, (_, test_ind) in zip(range(cv_object.n_splits), cv_object.split(x, y)):\n",
    "        ypred = scores['estimator'][i].predict(x[test_ind])\n",
    "        ytrue = y[test_ind]\n",
    "        amount = data['Amount'].values[test_ind]\n",
    "        results.append(cost_saving(ytrue, ypred, amount))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to return a dataframe of metrics results for each fold in our cv\n",
    "def get_metric_scores(scores, x, y, cv_object=cv):\n",
    "    ind = ['split_'+str(n) for n in range(1, cv_object.n_splits+1)]\n",
    "    \n",
    "    scores_credit = pd.DataFrame(index=ind)\n",
    "    \n",
    "    scores_credit['f1_score'] = scores['test_f1']\n",
    "    scores_credit['auc_pr'] = scores['test_average_precision']\n",
    "    scores_credit['cost_savings'] = cost_saving_per_split(scores, x, y, cv_object)\n",
    "\n",
    "    return scores_credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Fraud Sensitive Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using minmaxscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.LinearSVC()\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "MMscaled_ = minmax.fit_transform(df)\n",
    "y= data.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_sensitive_scores = cross_validate(model, MMscaled_, y, \n",
    "                                        scoring=['f1', 'average_precision'], \n",
    "                                        cv=cv, n_jobs=4, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_pr</th>\n",
       "      <th>cost_savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split_1</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.699738</td>\n",
       "      <td>0.339043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_2</th>\n",
       "      <td>0.719212</td>\n",
       "      <td>0.809325</td>\n",
       "      <td>0.424241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_3</th>\n",
       "      <td>0.715686</td>\n",
       "      <td>0.789719</td>\n",
       "      <td>0.525291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_4</th>\n",
       "      <td>0.702439</td>\n",
       "      <td>0.733629</td>\n",
       "      <td>0.409104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1_score    auc_pr  cost_savings\n",
       "split_1  0.666667  0.699738      0.339043\n",
       "split_2  0.719212  0.809325      0.424241\n",
       "split_3  0.715686  0.789719      0.525291\n",
       "split_4  0.702439  0.733629      0.409104"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_sensitive_results = get_metric_scores(fraud_sensitive_scores, MMscaled_,y)\n",
    "fraud_sensitive_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1_score        0.701001\n",
       "auc_pr          0.758103\n",
       "cost_savings    0.424420\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_sensitive_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Sensitive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = np.array([data['Amount'][ind] if fraud else admin_cost for ind, fraud in enumerate(y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_sensitive_model = svm.LinearSVC()\n",
    "cost_sensitive_scores = cross_validate(cost_sensitive_model, MMscaled_, y, \n",
    "                                       scoring=['f1', 'average_precision'], \n",
    "                                       cv=cv, n_jobs=4, return_estimator=True, \n",
    "                                       fit_params={'sample_weight': sample_weights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_pr</th>\n",
       "      <th>cost_savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split_1</th>\n",
       "      <td>0.777328</td>\n",
       "      <td>0.689966</td>\n",
       "      <td>0.736774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_2</th>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.797832</td>\n",
       "      <td>0.756566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_3</th>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.771564</td>\n",
       "      <td>0.817012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_4</th>\n",
       "      <td>0.806584</td>\n",
       "      <td>0.731759</td>\n",
       "      <td>0.735118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1_score    auc_pr  cost_savings\n",
       "split_1  0.777328  0.689966      0.736774\n",
       "split_2  0.816000  0.797832      0.756566\n",
       "split_3  0.841202  0.771564      0.817012\n",
       "split_4  0.806584  0.731759      0.735118"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_sensitive_results = get_metric_scores(cost_sensitive_scores, MMscaled_, y)\n",
    "cost_sensitive_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1_score        0.810279\n",
       "auc_pr          0.747780\n",
       "cost_savings    0.761367\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_sensitive_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score: 0.9249071541489905\n",
      "f-score: 0.12899336949969858\n",
      "roc_auc_score: 0.9565059694829422\n",
      "f-score: 0.1279199110122358\n",
      "roc_auc_score: 0.965740455741619\n",
      "f-score: 0.14242239805234327\n",
      "roc_auc_score: 0.9252376354203341\n",
      "f-score: 0.1327543424317618\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "smote = SMOTE()\n",
    "\n",
    "for train_idx, test_idx, in cv.split(MMscaled_, y):\n",
    "    X_train, y_train = MMscaled_[train_idx], y[train_idx]\n",
    "    X_test, y_test = MMscaled_[test_idx], y[test_idx]\n",
    "    X_train_oversampled, y_train_oversampled = smote.fit_sample(X_train, y_train)\n",
    "    smote_gradient_model = svm.LinearSVC()\n",
    "    smote_gradient_model.fit(X_train_oversampled, y_train_oversampled )  \n",
    "    pred = smote_gradient_model.predict(X_test)\n",
    "    print(f'roc_auc_score: {roc_auc_score(y_test, pred)}')\n",
    "    print(f'f-score: {f1_score(y_test, pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a pipeline with minmaxscaler plus LinearSVC, and prescaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a pipeline \n",
    "clf = make_pipeline(MinMaxScaler(),\n",
    "                   svm.LinearSVC(tol=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.84      0.55      0.67       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.92      0.78      0.83     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.91      0.59      0.71       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.96      0.79      0.86     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.90      0.59      0.72       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.95      0.80      0.86     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71078\n",
      "           1       0.88      0.59      0.70       123\n",
      "\n",
      "    accuracy                           1.00     71201\n",
      "   macro avg       0.94      0.79      0.85     71201\n",
      "weighted avg       1.00      1.00      1.00     71201\n",
      "\n",
      "F1_scores [0.6666666666666666, 0.7128712871287128, 0.7156862745098039, 0.7024390243902439]\n",
      "roc_auc_scores [0.7763313166833605, 0.7926336858438859, 0.7966916920678092, 0.7926125815747592]\n",
      "Wall time: 21.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f1_pipeline_scores =[]\n",
    "auc_pipeline_scores = []\n",
    "\n",
    "for train, test in cv.split(MMscaled_, y):\n",
    "#     df.reset_index(inplace=True)\n",
    "    Xtr, ytr = MMscaled_[train], y[train]\n",
    "    xte, yte = MMscaled_[test], y[test]\n",
    "    clf.fit(Xtr,ytr)\n",
    "    y_pred = clf.predict(xte)\n",
    "    f1_pipeline_scores.append(f1_score(yte,y_pred))\n",
    "    auc_pipeline_scores.append(roc_auc_score(yte,y_pred))\n",
    "    print(classification_report(yte,y_pred))\n",
    "print('F1_scores', f1_pipeline_scores)\n",
    "print('roc_auc_scores', auc_pipeline_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Very good f1 scores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fraud Sensistive Model\n",
    "\n",
    "#### Using Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using standardScaler \n",
    "\n",
    "fraud_sensitive_model = svm.LinearSVC()\n",
    "\n",
    "Scale = StandardScaler()\n",
    "SSscaled = Scale.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_sensitive_scores = cross_validate(fraud_sensitive_model, SSscaled, y, \n",
    "                                        scoring=['f1', 'average_precision'], \n",
    "                                        cv=cv, n_jobs=4, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_pr</th>\n",
       "      <th>cost_savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split_1</th>\n",
       "      <td>0.160584</td>\n",
       "      <td>0.628154</td>\n",
       "      <td>0.036421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_2</th>\n",
       "      <td>0.801802</td>\n",
       "      <td>0.787664</td>\n",
       "      <td>0.666093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_3</th>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.780348</td>\n",
       "      <td>0.776389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_4</th>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.723842</td>\n",
       "      <td>0.364603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1_score    auc_pr  cost_savings\n",
       "split_1  0.160584  0.628154      0.036421\n",
       "split_2  0.801802  0.787664      0.666093\n",
       "split_3  0.826087  0.780348      0.776389\n",
       "split_4  0.649485  0.723842      0.364603"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_sensitive_results = get_metric_scores(fraud_sensitive_scores, SSscaled,y)\n",
    "fraud_sensitive_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1_score        0.609489\n",
       "auc_pr          0.730002\n",
       "cost_savings    0.460876\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_sensitive_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Sensitive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = np.array([data['Amount'][ind] if fraud else admin_cost for ind, fraud in enumerate(y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_sensitive_model = svm.LinearSVC()\n",
    "cost_sensitive_scores = cross_validate(cost_sensitive_model, SSscaled, y, \n",
    "                                       scoring=['f1', 'average_precision'], \n",
    "                                       cv=cv, n_jobs=4, return_estimator=True, \n",
    "                                       fit_params={'sample_weight': sample_weights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_pr</th>\n",
       "      <th>cost_savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split_1</th>\n",
       "      <td>0.721461</td>\n",
       "      <td>0.679697</td>\n",
       "      <td>0.500724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_2</th>\n",
       "      <td>0.805310</td>\n",
       "      <td>0.783174</td>\n",
       "      <td>0.687852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_3</th>\n",
       "      <td>0.836207</td>\n",
       "      <td>0.770117</td>\n",
       "      <td>0.794888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_4</th>\n",
       "      <td>0.813278</td>\n",
       "      <td>0.731691</td>\n",
       "      <td>0.735459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1_score    auc_pr  cost_savings\n",
       "split_1  0.721461  0.679697      0.500724\n",
       "split_2  0.805310  0.783174      0.687852\n",
       "split_3  0.836207  0.770117      0.794888\n",
       "split_4  0.813278  0.731691      0.735459"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_sensitive_results = get_metric_scores(cost_sensitive_scores, SSscaled,y)\n",
    "cost_sensitive_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1_score        0.794064\n",
       "auc_pr          0.741170\n",
       "cost_savings    0.679731\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_sensitive_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADELEKE OLADAPO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score: 0.9249282574284401\n",
      "f-score: 0.12922705314009664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADELEKE OLADAPO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score: 0.9559010088053863\n",
      "f-score: 0.12208067940552014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADELEKE OLADAPO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score: 0.9612955560611192\n",
      "f-score: 0.13679245283018868\n",
      "roc_auc_score: 0.9286484652038057\n",
      "f-score: 0.12661195779601406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADELEKE OLADAPO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "# testing with balanced data\n",
    "smote = SMOTE()\n",
    "\n",
    "for train_idx, test_idx, in cv.split(SSscaled, y):\n",
    "    X_train, y_train = SSscaled[train_idx], y[train_idx]\n",
    "    X_test, y_test = SSscaled[test_idx], y[test_idx]\n",
    "    X_train_oversampled, y_train_oversampled = smote.fit_sample(X_train, y_train)\n",
    "    smote_gradient_model = svm.LinearSVC()\n",
    "    smote_gradient_model.fit(X_train_oversampled, y_train_oversampled )  \n",
    "    pred = smote_gradient_model.predict(X_test)\n",
    "    print(f'roc_auc_score: {roc_auc_score(y_test, pred)}')\n",
    "    print(f'f-score: {f1_score(y_test, pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smote gave a poor f1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selected new features using feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time     -0.012323\n",
       "V1       -0.101347\n",
       "V2        0.091289\n",
       "V3       -0.192961\n",
       "V4        0.133447\n",
       "V5       -0.094974\n",
       "V6       -0.043643\n",
       "V7       -0.187257\n",
       "V8        0.019875\n",
       "V9       -0.097733\n",
       "V10      -0.216883\n",
       "V11       0.154876\n",
       "V12      -0.260593\n",
       "V13      -0.004570\n",
       "V14      -0.302544\n",
       "V15      -0.004223\n",
       "V16      -0.196539\n",
       "V17      -0.326481\n",
       "V18      -0.111485\n",
       "V19       0.034783\n",
       "V20       0.020090\n",
       "V21       0.040413\n",
       "V22       0.000805\n",
       "V23      -0.002685\n",
       "V24      -0.007221\n",
       "V25       0.003308\n",
       "V26       0.004455\n",
       "V27       0.017580\n",
       "V28       0.009536\n",
       "Amount    0.005632\n",
       "Class     1.000000\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr().Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(data.corr(), linecolor='k', linewidths=.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection module \n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =data.drop('Class', 1)\n",
    "y = data.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feats = SelectKBest(score_func=f_classif, k= 20)\n",
    "fit = best_feats.fit(x,y)\n",
    "df_score = pd.DataFrame(fit.scores_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe to show our findings\n",
    "df_columns = pd.DataFrame(x.columns)\n",
    "important = pd.concat([df_columns, df_score], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "important.columns = ['Spec', 'Score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spec</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>V17</td>\n",
       "      <td>33979.168593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>V14</td>\n",
       "      <td>28695.547788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>V12</td>\n",
       "      <td>20749.822361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>V10</td>\n",
       "      <td>14057.979985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>V16</td>\n",
       "      <td>11443.349428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V3</td>\n",
       "      <td>11014.508305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>V7</td>\n",
       "      <td>10349.605408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>V11</td>\n",
       "      <td>6999.355047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V4</td>\n",
       "      <td>5163.832114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>V18</td>\n",
       "      <td>3584.380605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V1</td>\n",
       "      <td>2955.668946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>V9</td>\n",
       "      <td>2746.600273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>V5</td>\n",
       "      <td>2592.357929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V2</td>\n",
       "      <td>2393.401678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>V6</td>\n",
       "      <td>543.510578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>V21</td>\n",
       "      <td>465.916251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>V19</td>\n",
       "      <td>344.990997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>V20</td>\n",
       "      <td>114.999731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>V8</td>\n",
       "      <td>112.548287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>V27</td>\n",
       "      <td>88.045296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Time</td>\n",
       "      <td>43.252998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>V28</td>\n",
       "      <td>25.901405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>V24</td>\n",
       "      <td>14.850932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Amount</td>\n",
       "      <td>9.033345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>V13</td>\n",
       "      <td>5.947672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>V26</td>\n",
       "      <td>5.653653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>V15</td>\n",
       "      <td>5.080193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>V25</td>\n",
       "      <td>3.116062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>V23</td>\n",
       "      <td>2.053476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>V22</td>\n",
       "      <td>0.184706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Spec         Score\n",
       "17     V17  33979.168593\n",
       "14     V14  28695.547788\n",
       "12     V12  20749.822361\n",
       "10     V10  14057.979985\n",
       "16     V16  11443.349428\n",
       "3       V3  11014.508305\n",
       "7       V7  10349.605408\n",
       "11     V11   6999.355047\n",
       "4       V4   5163.832114\n",
       "18     V18   3584.380605\n",
       "1       V1   2955.668946\n",
       "9       V9   2746.600273\n",
       "5       V5   2592.357929\n",
       "2       V2   2393.401678\n",
       "6       V6    543.510578\n",
       "21     V21    465.916251\n",
       "19     V19    344.990997\n",
       "20     V20    114.999731\n",
       "8       V8    112.548287\n",
       "27     V27     88.045296\n",
       "0     Time     43.252998\n",
       "28     V28     25.901405\n",
       "24     V24     14.850932\n",
       "29  Amount      9.033345\n",
       "13     V13      5.947672\n",
       "26     V26      5.653653\n",
       "15     V15      5.080193\n",
       "25     V25      3.116062\n",
       "23     V23      2.053476\n",
       "22     V22      0.184706"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important.sort_values('Score', ascending=False, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used 14 as the miniumum because it looked most reasonable as the least value for correlation\n",
    "\n",
    "important_feats = list((important.loc[important.Score  > 14.0, 'Spec']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Time',\n",
       " 'V1',\n",
       " 'V2',\n",
       " 'V3',\n",
       " 'V4',\n",
       " 'V5',\n",
       " 'V6',\n",
       " 'V7',\n",
       " 'V8',\n",
       " 'V9',\n",
       " 'V10',\n",
       " 'V11',\n",
       " 'V12',\n",
       " 'V14',\n",
       " 'V16',\n",
       " 'V17',\n",
       " 'V18',\n",
       " 'V19',\n",
       " 'V20',\n",
       " 'V21',\n",
       " 'V24',\n",
       " 'V27',\n",
       " 'V28']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the most important fatures \n",
    "important_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(important_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So there are 23 important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = data[important_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V14</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V24</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>4.626942</td>\n",
       "      <td>1.107641</td>\n",
       "      <td>1.991691</td>\n",
       "      <td>0.510632</td>\n",
       "      <td>-0.682920</td>\n",
       "      <td>1.475829</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.675143</td>\n",
       "      <td>-0.711757</td>\n",
       "      <td>-0.025693</td>\n",
       "      <td>-1.221179</td>\n",
       "      <td>-1.545556</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.510602</td>\n",
       "      <td>0.140716</td>\n",
       "      <td>0.313502</td>\n",
       "      <td>0.395652</td>\n",
       "      <td>-0.577252</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.449624</td>\n",
       "      <td>-0.608577</td>\n",
       "      <td>0.509928</td>\n",
       "      <td>1.113981</td>\n",
       "      <td>2.897849</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084316</td>\n",
       "      <td>-0.302620</td>\n",
       "      <td>-0.660377</td>\n",
       "      <td>0.167430</td>\n",
       "      <td>-0.256117</td>\n",
       "      <td>0.382948</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V14       V16  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.311169 -0.470401   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.143772  0.463917   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ... -0.165946 -2.890083   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.287924 -1.059647   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -1.119670 -0.451449   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  4.626942  1.107641   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ... -0.675143 -0.711757   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ... -0.510602  0.140716   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.449624 -0.608577   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ... -0.084316 -0.302620   \n",
       "\n",
       "             V17       V18       V19       V20       V21       V24       V27  \\\n",
       "0       0.207971  0.025791  0.403993  0.251412 -0.018307  0.066928  0.133558   \n",
       "1      -0.114805 -0.183361 -0.145783 -0.069083 -0.225775 -0.339846 -0.008983   \n",
       "2       1.109969 -0.121359 -2.261857  0.524980  0.247998 -0.689281 -0.055353   \n",
       "3      -0.684093  1.965775 -1.232622 -0.208038 -0.108300 -1.175575  0.062723   \n",
       "4      -0.237033 -0.038195  0.803487  0.408542 -0.009431  0.141267  0.219422   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  1.991691  0.510632 -0.682920  1.475829  0.213454 -0.509348  0.943651   \n",
       "284803 -0.025693 -1.221179 -1.545556  0.059616  0.214205 -1.016226  0.068472   \n",
       "284804  0.313502  0.395652 -0.577252  0.001396  0.232045  0.640134  0.004455   \n",
       "284805  0.509928  1.113981  2.897849  0.127434  0.265245  0.123205  0.108821   \n",
       "284806 -0.660377  0.167430 -0.256117  0.382948  0.261057  0.008797 -0.002415   \n",
       "\n",
       "             V28  \n",
       "0      -0.021053  \n",
       "1       0.014724  \n",
       "2      -0.059752  \n",
       "3       0.061458  \n",
       "4       0.215153  \n",
       "...          ...  \n",
       "284802  0.823731  \n",
       "284803 -0.053527  \n",
       "284804 -0.026561  \n",
       "284805  0.104533  \n",
       "284806  0.013649  \n",
       "\n",
       "[284807 rows x 23 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Sensitive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard = StandardScaler()\n",
    "scaled_new = standard.fit_transform(new_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.99658302, -0.69424232, -0.04407492, ...,  0.11050692,\n",
       "         0.33089162, -0.06378115],\n",
       "       [-1.99658302,  0.60849633,  0.16117592, ..., -0.56113055,\n",
       "        -0.02225568,  0.04460752],\n",
       "       [-1.99656197, -0.69350046, -0.81157783, ..., -1.13809214,\n",
       "        -0.13713686, -0.18102083],\n",
       "       ...,\n",
       "       [ 1.6419735 ,  0.98002374, -0.18243372, ...,  1.05694395,\n",
       "         0.01103672, -0.0804672 ],\n",
       "       [ 1.6419735 , -0.12275539,  0.32125034, ...,  0.20342782,\n",
       "         0.26960398,  0.31668678],\n",
       "       [ 1.64205773, -0.27233093, -0.11489898, ...,  0.01452561,\n",
       "        -0.00598394,  0.04134999]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.LinearSVC()\n",
    "cv = StratifiedKFold(shuffle=True,random_state=1, n_splits=4)\n",
    "fraud_sensitive_scores = cross_validate(model, scaled_new, y, \n",
    "                                        scoring=['f1', 'average_precision'], \n",
    "                                        cv=cv, n_jobs=4, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_pr</th>\n",
       "      <th>cost_savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split_1</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.712229</td>\n",
       "      <td>0.720077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_2</th>\n",
       "      <td>0.659794</td>\n",
       "      <td>0.791516</td>\n",
       "      <td>0.353107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_3</th>\n",
       "      <td>0.810573</td>\n",
       "      <td>0.795352</td>\n",
       "      <td>0.697981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_4</th>\n",
       "      <td>0.805310</td>\n",
       "      <td>0.743542</td>\n",
       "      <td>0.692268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1_score    auc_pr  cost_savings\n",
       "split_1  0.800000  0.712229      0.720077\n",
       "split_2  0.659794  0.791516      0.353107\n",
       "split_3  0.810573  0.795352      0.697981\n",
       "split_4  0.805310  0.743542      0.692268"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_sensitive_results = get_metric_scores(fraud_sensitive_scores,scaled_new,y)\n",
    "fraud_sensitive_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1_score        0.768919\n",
       "auc_pr          0.760660\n",
       "cost_savings    0.615858\n",
       "dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_sensitive_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the improved scores due to new features selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Sensitive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = np.array([data['Amount'][ind] if fraud else admin_cost for ind, fraud in enumerate(y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cost_sensitive_model = svm.LinearSVC()\n",
    "cost_sensitive_scores = cross_validate(cost_sensitive_model, scaled_new, y, \n",
    "                                       scoring=['f1', 'average_precision'], \n",
    "                                       cv=cv, n_jobs=4, return_estimator=True, \n",
    "                                       fit_params={'sample_weight': sample_weights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_pr</th>\n",
       "      <th>cost_savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split_1</th>\n",
       "      <td>0.778243</td>\n",
       "      <td>0.670575</td>\n",
       "      <td>0.715228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_2</th>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.793841</td>\n",
       "      <td>0.757007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_3</th>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.754956</td>\n",
       "      <td>0.816492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_4</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.710346</td>\n",
       "      <td>0.647868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1_score    auc_pr  cost_savings\n",
       "split_1  0.778243  0.670575      0.715228\n",
       "split_2  0.822581  0.793841      0.757007\n",
       "split_3  0.830508  0.754956      0.816492\n",
       "split_4  0.785714  0.710346      0.647868"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_sensitive_results = get_metric_scores(cost_sensitive_scores, scaled_new, y)\n",
    "cost_sensitive_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1_score        0.804262\n",
       "auc_pr          0.732429\n",
       "cost_savings    0.734149\n",
       "dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_sensitive_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Mininmum Risk (BMR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: cost dependent classification is also called Bayes Mininmum Risk.\n",
    "***see more about BMR [here](https://link.springer.com/article/10.1007/s42452-020-03375-w)***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# because LinearSVC doesnt have predict proba funcion \n",
    "cclf = CalibratedClassifierCV(base_estimator=svm.LinearSVC(penalty='l2', dual=False), cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmr_model = cclf\n",
    "bmr_scores = cross_validate(bmr_model, scaled_new, y,\n",
    "                            cv=cv, n_jobs=4,\n",
    "                            return_estimator=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating AUC PR curve is not possible for BMR because predictions are based on minimum expected cost and not on probability. For this reason, we will calculate only f1_score and cost-savings for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to predict based on the predicting that will minimize the expected cost.\n",
    "def bmr_predict(model, x, trans_cost):\n",
    "    prob = model.predict_proba(x)[:, 1]\n",
    "        \n",
    "    expected_cost_0 = prob * trans_cost\n",
    "    expected_cost_1 = (1-prob) * admin_cost\n",
    "        \n",
    "    pred = (expected_cost_1 < expected_cost_0).astype(int)\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bmr_metric_scores(scores, x, y=y, cv_object=cv):\n",
    "    ind = ['split_'+str(n) for n in range(1, cv_object.n_splits+1)]\n",
    "    scores_df = pd.DataFrame(index=ind)\n",
    "\n",
    "    f1_results = []\n",
    "    cs_results = []\n",
    "    \n",
    "    for i, (_, test_ind) in zip(range(cv_object.n_splits), cv_object.split(x, y)):\n",
    "        amount = data['Amount'].values[test_ind]\n",
    "        \n",
    "        ypred = bmr_predict(scores['estimator'][i], x[test_ind], amount)\n",
    "        ytrue = y[test_ind]\n",
    "                \n",
    "        f1_results.append(f1_score(ytrue, ypred))\n",
    "        cs_results.append(cost_saving(ytrue, ypred, amount))\n",
    "        \n",
    "    scores_df['f1_score'] = f1_results\n",
    "    #scores_df['auc_pr'] = scores['test_average_precision']\n",
    "    scores_df['cost_savings'] = cs_results\n",
    "\n",
    "    return scores_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>cost_savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split_1</th>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.732866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_2</th>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.750969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_3</th>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.813648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_4</th>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.727988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1_score  cost_savings\n",
       "split_1  0.641509      0.732866\n",
       "split_2  0.689655      0.750969\n",
       "split_3  0.742857      0.813648\n",
       "split_4  0.629630      0.727988"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmr_results = get_bmr_metric_scores(bmr_scores, scaled_new,y)\n",
    "bmr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1_score        0.675913\n",
       "cost_savings    0.756368\n",
       "dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmr_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the new baseline model selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df = data.drop(['V25','Time','Amount', 'Class'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510632</td>\n",
       "      <td>-0.682920</td>\n",
       "      <td>1.475829</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.221179</td>\n",
       "      <td>-1.545556</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395652</td>\n",
       "      <td>-0.577252</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>...</td>\n",
       "      <td>1.113981</td>\n",
       "      <td>2.897849</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167430</td>\n",
       "      <td>-0.256117</td>\n",
       "      <td>0.382948</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V1         V2        V3        V4        V5        V6  \\\n",
       "0       -1.359807  -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1        1.191857   0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       -1.358354  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       -0.966272  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       -1.158233   0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "284802 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n",
       "284803  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
       "284804   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
       "284805  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
       "284806  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
       "\n",
       "              V7        V8        V9       V10  ...       V18       V19  \\\n",
       "0       0.239599  0.098698  0.363787  0.090794  ...  0.025791  0.403993   \n",
       "1      -0.078803  0.085102 -0.255425 -0.166974  ... -0.183361 -0.145783   \n",
       "2       0.791461  0.247676 -1.514654  0.207643  ... -0.121359 -2.261857   \n",
       "3       0.237609  0.377436 -1.387024 -0.054952  ...  1.965775 -1.232622   \n",
       "4       0.592941 -0.270533  0.817739  0.753074  ... -0.038195  0.803487   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -4.918215  7.305334  1.914428  4.356170  ...  0.510632 -0.682920   \n",
       "284803  0.024330  0.294869  0.584800 -0.975926  ... -1.221179 -1.545556   \n",
       "284804 -0.296827  0.708417  0.432454 -0.484782  ...  0.395652 -0.577252   \n",
       "284805 -0.686180  0.679145  0.392087 -0.399126  ...  1.113981  2.897849   \n",
       "284806  1.577006 -0.414650  0.486180 -0.915427  ...  0.167430 -0.256117   \n",
       "\n",
       "             V20       V21       V22       V23       V24       V26       V27  \\\n",
       "0       0.251412 -0.018307  0.277838 -0.110474  0.066928 -0.189115  0.133558   \n",
       "1      -0.069083 -0.225775 -0.638672  0.101288 -0.339846  0.125895 -0.008983   \n",
       "2       0.524980  0.247998  0.771679  0.909412 -0.689281 -0.139097 -0.055353   \n",
       "3      -0.208038 -0.108300  0.005274 -0.190321 -1.175575 -0.221929  0.062723   \n",
       "4       0.408542 -0.009431  0.798278 -0.137458  0.141267  0.502292  0.219422   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  1.475829  0.213454  0.111864  1.014480 -0.509348  0.250034  0.943651   \n",
       "284803  0.059616  0.214205  0.924384  0.012463 -1.016226 -0.395255  0.068472   \n",
       "284804  0.001396  0.232045  0.578229 -0.037501  0.640134 -0.087371  0.004455   \n",
       "284805  0.127434  0.265245  0.800049 -0.163298  0.123205  0.546668  0.108821   \n",
       "284806  0.382948  0.261057  0.643078  0.376777  0.008797 -0.818267 -0.002415   \n",
       "\n",
       "             V28  \n",
       "0      -0.021053  \n",
       "1       0.014724  \n",
       "2      -0.059752  \n",
       "3       0.061458  \n",
       "4       0.215153  \n",
       "...          ...  \n",
       "284802  0.823731  \n",
       "284803 -0.053527  \n",
       "284804 -0.026561  \n",
       "284805  0.104533  \n",
       "284806  0.013649  \n",
       "\n",
       "[284807 rows x 27 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Sensitive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard = StandardScaler()\n",
    "scaled_base = standard.fit_transform(baseline_df)\n",
    "model = svm.LinearSVC(tol= 1e-5, class_weight='balanced',\n",
    "                     max_iter = 1500, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(shuffle=True, random_state=1,n_splits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fraud_sensitive_scores = cross_validate(model, scaled_base, y, \n",
    "                                        scoring=['f1', 'average_precision'], \n",
    "                                        cv=cv, n_jobs=4, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_pr</th>\n",
       "      <th>cost_savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split_1</th>\n",
       "      <td>0.743083</td>\n",
       "      <td>0.683361</td>\n",
       "      <td>0.703650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_2</th>\n",
       "      <td>0.779923</td>\n",
       "      <td>0.772225</td>\n",
       "      <td>0.719289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_3</th>\n",
       "      <td>0.787645</td>\n",
       "      <td>0.762658</td>\n",
       "      <td>0.806509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_4</th>\n",
       "      <td>0.751938</td>\n",
       "      <td>0.712546</td>\n",
       "      <td>0.718814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1_score    auc_pr  cost_savings\n",
       "split_1  0.743083  0.683361      0.703650\n",
       "split_2  0.779923  0.772225      0.719289\n",
       "split_3  0.787645  0.762658      0.806509\n",
       "split_4  0.751938  0.712546      0.718814"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_sensitive_results = get_metric_scores(fraud_sensitive_scores,scaled_base,y)\n",
    "fraud_sensitive_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1_score        0.765647\n",
       "auc_pr          0.732698\n",
       "cost_savings    0.737066\n",
       "dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_sensitive_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the improved scores due to new features selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Sensitive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = np.array([data['Amount'][ind] if fraud else admin_cost for ind, fraud in enumerate(y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cost_sensitive_model = svm.LinearSVC()\n",
    "cost_sensitive_scores = cross_validate(cost_sensitive_model, scaled_base, y, \n",
    "                                       scoring=['f1', 'average_precision'], \n",
    "                                       cv=cv, n_jobs=4, return_estimator=True, \n",
    "                                       fit_params={'sample_weight': sample_weights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_sensitive_results = get_metric_scores(cost_sensitive_scores, scaled_base, y)\n",
    "cost_sensitive_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_sensitive_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Mininmum Risk (BMR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: cost dependent classification is also called Bayes Mininmum Risk.\n",
    "***see more about BMR [here](https://link.springer.com/article/10.1007/s42452-020-03375-w)***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# because LinearSVC doesnt have predict proba funcion \n",
    "cclf = CalibratedClassifierCV(base_estimator=svm.LinearSVC(penalty='l2', dual=False), cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmr_model = cclf\n",
    "bmr_scores = cross_validate(bmr_model, scaled_base, y,\n",
    "                            cv=cv, n_jobs=4,\n",
    "                            return_estimator=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating AUC PR curve is not possible for BMR because predictions are based on minimum expected cost and not on probability. For this reason, we will calculate only f1_score and cost-savings for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to predict based on the predicting that will minimize the expected cost.\n",
    "def bmr_predict(model, x, trans_cost):\n",
    "    prob = model.predict_proba(x)[:, 1]\n",
    "        \n",
    "    expected_cost_0 = prob * trans_cost\n",
    "    expected_cost_1 = (1-prob) * admin_cost\n",
    "        \n",
    "    pred = (expected_cost_1 < expected_cost_0).astype(int)\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bmr_metric_scores(scores, x, y=y, cv_object=cv):\n",
    "    ind = ['split_'+str(n) for n in range(1, cv_object.n_splits+1)]\n",
    "    scores_df = pd.DataFrame(index=ind)\n",
    "\n",
    "    f1_results = []\n",
    "    cs_results = []\n",
    "    \n",
    "    for i, (_, test_ind) in zip(range(cv_object.n_splits), cv_object.split(x, y)):\n",
    "        amount = data['Amount'].values[test_ind]\n",
    "        \n",
    "        ypred = bmr_predict(scores['estimator'][i], x[test_ind], amount)\n",
    "        ytrue = y[test_ind]\n",
    "                \n",
    "        f1_results.append(f1_score(ytrue, ypred))\n",
    "        cs_results.append(cost_saving(ytrue, ypred, amount))\n",
    "        \n",
    "    scores_df['f1_score'] = f1_results\n",
    "    #scores_df['auc_pr'] = scores['test_average_precision']\n",
    "    scores_df['cost_savings'] = cs_results\n",
    "\n",
    "    return scores_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmr_results = get_bmr_metric_scores(bmr_scores, scaled_base,y)\n",
    "bmr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmr_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
