{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import f1_score, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/defaultuser0/Desktop/folders/Hamoye/g01-fraud-detection/data/creditcard.csv')\n",
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['V'+str(i) for i in range(1, 29) if i != 25]\n",
    "\n",
    "X = df[cols]\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,random_state=42, shuffle=True, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on validation:  0.09191880505553426\n",
      "f1 score on training:  0.1189300411522634\n"
     ]
    }
   ],
   "source": [
    "print('F1 score on validation: ', f1_score(y_test, pred))\n",
    "print('f1 score on training: ', f1_score(y_train, gnb.predict(X_train_sc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=1)\n",
    "admin_cost = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to calculate cost savings\n",
    "def cost_saving(ytrue, ypred, amount):\n",
    "    fp = np.sum((ytrue == 0) & (ypred == 1))\n",
    "    cost = np.sum(fp*admin_cost) + np.sum((amount[(ytrue == 1) & (ypred == 0)]))\n",
    "    max_cost = np.sum((amount[(ytrue == 1)]))\n",
    "    savings = 1 - (cost/max_cost)\n",
    "    \n",
    "    return savings\n",
    "\n",
    "# defining a function to calculate cost saving per fold (splits) of our cv\n",
    "def cost_saving_per_split(scores, x, y, cv_object):\n",
    "    results = []\n",
    "    for i, (_, test_ind) in zip(range(cv_object.n_splits), cv_object.split(x, y)):\n",
    "        ypred = scores['estimator'][i].predict(x[test_ind])\n",
    "        ytrue = y[test_ind]\n",
    "        amount = df['Amount'].values[test_ind]\n",
    "        results.append(cost_saving(ytrue, ypred, amount))\n",
    "        \n",
    "    return results\n",
    "\n",
    "# defining a function to return a dataframe of metrics results for each fold in our cv\n",
    "def get_metric_scores(scores, x, y=y, cv_object=cv):\n",
    "    #ind = ['split_'+str(n) for n in range(1, cv_object.n_splits+1)]\n",
    "    \n",
    "    scores_df = pd.DataFrame()\n",
    "    \n",
    "    scores_df['f1_score'] = scores['test_f1']\n",
    "    scores_df['auc_pr'] = scores['test_average_precision']\n",
    "    scores_df['cost_savings'] = cost_saving_per_split(scores, x, y, cv_object)\n",
    "\n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc0 = StandardScaler()\n",
    "fraud_sensitive_pipe = Pipeline([('scaler', sc0), ('model', gnb)])\n",
    "\n",
    "fraud_sensitive_scores = cross_validate(fraud_sensitive_pipe, np.array(X), y, \\\n",
    "                            scoring=['f1', 'average_precision'], cv=cv, n_jobs=4, \\\n",
    "                                        return_estimator=True, error_score='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fraud Sensitive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_pr</th>\n",
       "      <th>cost_savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.110681</td>\n",
       "      <td>0.077734</td>\n",
       "      <td>0.540069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.114127</td>\n",
       "      <td>0.083457</td>\n",
       "      <td>0.379573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.119678</td>\n",
       "      <td>0.098892</td>\n",
       "      <td>0.557511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.118129</td>\n",
       "      <td>0.089255</td>\n",
       "      <td>0.486035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score    auc_pr  cost_savings\n",
       "0  0.110681  0.077734      0.540069\n",
       "1  0.114127  0.083457      0.379573\n",
       "2  0.119678  0.098892      0.557511\n",
       "3  0.118129  0.089255      0.486035"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_sensitive_results = get_metric_scores(fraud_sensitive_scores, np.array(X))\n",
    "fraud_sensitive_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1_score        0.115654\n",
       "auc_pr          0.087334\n",
       "cost_savings    0.490797\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_sensitive_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = np.array([df['Amount'][ind] if fraud else admin_cost for ind, fraud in enumerate(y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc1 = StandardScaler()\n",
    "cost_sensitive_pipe = Pipeline([('scaler', sc1), ('model', gnb)])\n",
    "\n",
    "cost_sensitive_scores = cross_validate(cost_sensitive_pipe, np.array(X), y, \\\n",
    "                        scoring=['f1', 'average_precision'], cv=cv, n_jobs=4, return_estimator=True, \\\n",
    "                          fit_params={'model__sample_weight': sample_weights}, error_score='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cost Sensitive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_pr</th>\n",
       "      <th>cost_savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.098801</td>\n",
       "      <td>0.073916</td>\n",
       "      <td>0.613121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.101171</td>\n",
       "      <td>0.081660</td>\n",
       "      <td>0.343395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.103921</td>\n",
       "      <td>0.093017</td>\n",
       "      <td>0.516332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.101879</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.433300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score    auc_pr  cost_savings\n",
       "0  0.098801  0.073916      0.613121\n",
       "1  0.101171  0.081660      0.343395\n",
       "2  0.103921  0.093017      0.516332\n",
       "3  0.101879  0.086420      0.433300"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_sensitive_results = get_metric_scores(cost_sensitive_scores, np.array(X))\n",
    "cost_sensitive_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1_score        0.101443\n",
       "auc_pr          0.083754\n",
       "cost_savings    0.476537\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_sensitive_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler3 = StandardScaler()\n",
    "bmr_model = GaussianNB()\n",
    "\n",
    "bmr_pipe = Pipeline([('scaler', scaler3), ('model', bmr_model)])\n",
    "\n",
    "bmr_scores = cross_validate(bmr_pipe, np.array(X), y, cv=cv, n_jobs=4, return_estimator=True, \\\n",
    "                            error_score='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to predict based on the predicting that will minimize the expected cost.\n",
    "def bmr_predict(model, x, trans_cost):\n",
    "    prob = model.predict_proba(x)[:, 1]\n",
    "        \n",
    "    expected_cost_0 = prob * trans_cost\n",
    "    expected_cost_1 = (1-prob) * admin_cost\n",
    "        \n",
    "    pred = (expected_cost_1 < expected_cost_0).astype(int)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bmr_metric_scores(scores, x, y=y, cv_object=cv):\n",
    "    ind = ['split_'+str(n) for n in range(1, cv_object.n_splits+1)]\n",
    "    scores_df = pd.DataFrame(index=ind)\n",
    "\n",
    "    f1_results = []\n",
    "    cs_results = []\n",
    "    \n",
    "    for i, (_, test_ind) in zip(range(cv_object.n_splits), cv_object.split(x, y)):\n",
    "        amount = df['Amount'].values[test_ind]\n",
    "        \n",
    "        ypred = bmr_predict(scores['estimator'][i], x[test_ind], amount)\n",
    "        ytrue = y[test_ind]\n",
    "                \n",
    "        f1_results.append(f1_score(ytrue, ypred))\n",
    "        cs_results.append(cost_saving(ytrue, ypred, amount))\n",
    "        \n",
    "    scores_df['f1_score'] = f1_results\n",
    "    #scores_df['auc_pr'] = scores['test_average_precision']\n",
    "    scores_df['cost_savings'] = cs_results\n",
    "\n",
    "    return scores_df    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BMR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>cost_savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split_1</th>\n",
       "      <td>0.100481</td>\n",
       "      <td>0.531192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_2</th>\n",
       "      <td>0.104707</td>\n",
       "      <td>0.391490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_3</th>\n",
       "      <td>0.109709</td>\n",
       "      <td>0.563708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_4</th>\n",
       "      <td>0.102990</td>\n",
       "      <td>0.468298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1_score  cost_savings\n",
       "split_1  0.100481      0.531192\n",
       "split_2  0.104707      0.391490\n",
       "split_3  0.109709      0.563708\n",
       "split_4  0.102990      0.468298"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmr_results = get_bmr_metric_scores(bmr_scores, np.array(X))\n",
    "bmr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1_score        0.104472\n",
       "cost_savings    0.488672\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmr_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = SMOTE(random_state=1)\n",
    "clf = GaussianNB()\n",
    "X_train_smote, y_train_smote = sm.fit_sample(X_train, y_train)\n",
    "clf.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    199020\n",
       "0    199020\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_smote.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE F1 score on validation:  0.10262828535669587\n",
      "SMOTE f1 score on training:  0.9154286018245166\n",
      "\n",
      "SMOTE roc score on validation:  0.5271952356630193\n",
      "SMOTE roc score on training:  0.9253345651790054\n"
     ]
    }
   ],
   "source": [
    "print('SMOTE F1 score on validation: ', f1_score(pred1, y_test))\n",
    "print('SMOTE f1 score on training: ', f1_score(clf.predict(X_train_smote), y_train_smote))\n",
    "print()\n",
    "print('SMOTE roc score on validation: ', roc_auc_score(pred1, y_test))\n",
    "print('SMOTE roc score on training: ', roc_auc_score(clf.predict(X_train_smote), y_train_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fraud sensitive model after doing SMOTE oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "clf1 = GaussianNB()\n",
    "fraud_sensitive_pipe = Pipeline([('scaler', ss), ('model', clf1)])\n",
    "\n",
    "fraud_sensitive_scores = cross_validate(fraud_sensitive_pipe, np.array(X_train_smote), y_train_smote, \\\n",
    "                            scoring=['f1', 'average_precision'], cv=cv, n_jobs=4, \\\n",
    "                                        return_estimator=True, error_score='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_pr</th>\n",
       "      <th>cost_savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.915314</td>\n",
       "      <td>0.957256</td>\n",
       "      <td>0.508708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.915051</td>\n",
       "      <td>0.956882</td>\n",
       "      <td>0.378705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.915259</td>\n",
       "      <td>0.958436</td>\n",
       "      <td>0.546137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.916047</td>\n",
       "      <td>0.957912</td>\n",
       "      <td>0.444216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score    auc_pr  cost_savings\n",
       "0  0.915314  0.957256      0.508708\n",
       "1  0.915051  0.956882      0.378705\n",
       "2  0.915259  0.958436      0.546137\n",
       "3  0.916047  0.957912      0.444216"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_sensitive_results = get_metric_scores(fraud_sensitive_scores, np.array(X))\n",
    "fraud_sensitive_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1_score        0.915418\n",
       "auc_pr          0.957621\n",
       "cost_savings    0.469441\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_sensitive_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "- The fraud sensitive model with stratifiedKFold performed better on cost savings in relation to all other models, but in general it still had a poor performance\n",
    "- The F1 score greatly(from 0.1 to 0.9) imporved after oversampling, but this imrovement happened only on the training data and not on the testing data\n",
    "- over sampling did not favour cost saving\n",
    "\n",
    "### Challenge\n",
    "- GaussianNB model takes only 2 parameters, so hyperparameter tuning is not supported here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
