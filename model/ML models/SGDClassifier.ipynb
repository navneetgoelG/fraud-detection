{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n #   for filename in filenames:\n     #   print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import StratifiedKFold, cross_validate\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import f1_score\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/creditcardfraud/creditcard.csv')","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9  ...       V21       V22       V23       V24       V25  \\\n0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n\n        V26       V27       V28  Amount  Class  \n0 -0.189115  0.133558 -0.021053  149.62      0  \n1  0.125895 -0.008983  0.014724    2.69      0  \n2 -0.139097 -0.055353 -0.059752  378.66      0  \n3 -0.221929  0.062723  0.061458  123.50      0  \n4  0.502292  0.219422  0.215153   69.99      0  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 31 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":6,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 284807 entries, 0 to 284806\nData columns (total 31 columns):\n #   Column  Non-Null Count   Dtype  \n---  ------  --------------   -----  \n 0   Time    284807 non-null  float64\n 1   V1      284807 non-null  float64\n 2   V2      284807 non-null  float64\n 3   V3      284807 non-null  float64\n 4   V4      284807 non-null  float64\n 5   V5      284807 non-null  float64\n 6   V6      284807 non-null  float64\n 7   V7      284807 non-null  float64\n 8   V8      284807 non-null  float64\n 9   V9      284807 non-null  float64\n 10  V10     284807 non-null  float64\n 11  V11     284807 non-null  float64\n 12  V12     284807 non-null  float64\n 13  V13     284807 non-null  float64\n 14  V14     284807 non-null  float64\n 15  V15     284807 non-null  float64\n 16  V16     284807 non-null  float64\n 17  V17     284807 non-null  float64\n 18  V18     284807 non-null  float64\n 19  V19     284807 non-null  float64\n 20  V20     284807 non-null  float64\n 21  V21     284807 non-null  float64\n 22  V22     284807 non-null  float64\n 23  V23     284807 non-null  float64\n 24  V24     284807 non-null  float64\n 25  V25     284807 non-null  float64\n 26  V26     284807 non-null  float64\n 27  V27     284807 non-null  float64\n 28  V28     284807 non-null  float64\n 29  Amount  284807 non-null  float64\n 30  Class   284807 non-null  int64  \ndtypes: float64(30), int64(1)\nmemory usage: 67.4 MB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"                Time            V1            V2            V3            V4  \\\ncount  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \nstd     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \nmin         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \nmax    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n\n                 V5            V6            V7            V8            V9  \\\ncount  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \nstd    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \nmin   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \nmax    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n\n       ...           V21           V22           V23           V24  \\\ncount  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean   ...  1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \nstd    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \nmin    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \nmax    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n\n                V25           V26           V27           V28         Amount  \\\ncount  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \nmean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \nstd    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \nmin   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \nmax    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n\n               Class  \ncount  284807.000000  \nmean        0.001727  \nstd         0.041527  \nmin         0.000000  \n25%         0.000000  \n50%         0.000000  \n75%         0.000000  \nmax         1.000000  \n\n[8 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>284807.000000</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>...</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>284807.000000</td>\n      <td>284807.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>94813.859575</td>\n      <td>3.919560e-15</td>\n      <td>5.688174e-16</td>\n      <td>-8.769071e-15</td>\n      <td>2.782312e-15</td>\n      <td>-1.552563e-15</td>\n      <td>2.010663e-15</td>\n      <td>-1.694249e-15</td>\n      <td>-1.927028e-16</td>\n      <td>-3.137024e-15</td>\n      <td>...</td>\n      <td>1.537294e-16</td>\n      <td>7.959909e-16</td>\n      <td>5.367590e-16</td>\n      <td>4.458112e-15</td>\n      <td>1.453003e-15</td>\n      <td>1.699104e-15</td>\n      <td>-3.660161e-16</td>\n      <td>-1.206049e-16</td>\n      <td>88.349619</td>\n      <td>0.001727</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>47488.145955</td>\n      <td>1.958696e+00</td>\n      <td>1.651309e+00</td>\n      <td>1.516255e+00</td>\n      <td>1.415869e+00</td>\n      <td>1.380247e+00</td>\n      <td>1.332271e+00</td>\n      <td>1.237094e+00</td>\n      <td>1.194353e+00</td>\n      <td>1.098632e+00</td>\n      <td>...</td>\n      <td>7.345240e-01</td>\n      <td>7.257016e-01</td>\n      <td>6.244603e-01</td>\n      <td>6.056471e-01</td>\n      <td>5.212781e-01</td>\n      <td>4.822270e-01</td>\n      <td>4.036325e-01</td>\n      <td>3.300833e-01</td>\n      <td>250.120109</td>\n      <td>0.041527</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-5.640751e+01</td>\n      <td>-7.271573e+01</td>\n      <td>-4.832559e+01</td>\n      <td>-5.683171e+00</td>\n      <td>-1.137433e+02</td>\n      <td>-2.616051e+01</td>\n      <td>-4.355724e+01</td>\n      <td>-7.321672e+01</td>\n      <td>-1.343407e+01</td>\n      <td>...</td>\n      <td>-3.483038e+01</td>\n      <td>-1.093314e+01</td>\n      <td>-4.480774e+01</td>\n      <td>-2.836627e+00</td>\n      <td>-1.029540e+01</td>\n      <td>-2.604551e+00</td>\n      <td>-2.256568e+01</td>\n      <td>-1.543008e+01</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>54201.500000</td>\n      <td>-9.203734e-01</td>\n      <td>-5.985499e-01</td>\n      <td>-8.903648e-01</td>\n      <td>-8.486401e-01</td>\n      <td>-6.915971e-01</td>\n      <td>-7.682956e-01</td>\n      <td>-5.540759e-01</td>\n      <td>-2.086297e-01</td>\n      <td>-6.430976e-01</td>\n      <td>...</td>\n      <td>-2.283949e-01</td>\n      <td>-5.423504e-01</td>\n      <td>-1.618463e-01</td>\n      <td>-3.545861e-01</td>\n      <td>-3.171451e-01</td>\n      <td>-3.269839e-01</td>\n      <td>-7.083953e-02</td>\n      <td>-5.295979e-02</td>\n      <td>5.600000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>84692.000000</td>\n      <td>1.810880e-02</td>\n      <td>6.548556e-02</td>\n      <td>1.798463e-01</td>\n      <td>-1.984653e-02</td>\n      <td>-5.433583e-02</td>\n      <td>-2.741871e-01</td>\n      <td>4.010308e-02</td>\n      <td>2.235804e-02</td>\n      <td>-5.142873e-02</td>\n      <td>...</td>\n      <td>-2.945017e-02</td>\n      <td>6.781943e-03</td>\n      <td>-1.119293e-02</td>\n      <td>4.097606e-02</td>\n      <td>1.659350e-02</td>\n      <td>-5.213911e-02</td>\n      <td>1.342146e-03</td>\n      <td>1.124383e-02</td>\n      <td>22.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>139320.500000</td>\n      <td>1.315642e+00</td>\n      <td>8.037239e-01</td>\n      <td>1.027196e+00</td>\n      <td>7.433413e-01</td>\n      <td>6.119264e-01</td>\n      <td>3.985649e-01</td>\n      <td>5.704361e-01</td>\n      <td>3.273459e-01</td>\n      <td>5.971390e-01</td>\n      <td>...</td>\n      <td>1.863772e-01</td>\n      <td>5.285536e-01</td>\n      <td>1.476421e-01</td>\n      <td>4.395266e-01</td>\n      <td>3.507156e-01</td>\n      <td>2.409522e-01</td>\n      <td>9.104512e-02</td>\n      <td>7.827995e-02</td>\n      <td>77.165000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>172792.000000</td>\n      <td>2.454930e+00</td>\n      <td>2.205773e+01</td>\n      <td>9.382558e+00</td>\n      <td>1.687534e+01</td>\n      <td>3.480167e+01</td>\n      <td>7.330163e+01</td>\n      <td>1.205895e+02</td>\n      <td>2.000721e+01</td>\n      <td>1.559499e+01</td>\n      <td>...</td>\n      <td>2.720284e+01</td>\n      <td>1.050309e+01</td>\n      <td>2.252841e+01</td>\n      <td>4.584549e+00</td>\n      <td>7.519589e+00</td>\n      <td>3.517346e+00</td>\n      <td>3.161220e+01</td>\n      <td>3.384781e+01</td>\n      <td>25691.160000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 31 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Class'].value_counts()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"0    284315\n1       492\nName: Class, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit = df.copy()","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 27 most important features according to our EDA\ncols = ['V'+str(i) for i in range(1, 29) if i != 25]\nprint(cols)\n\n","execution_count":10,"outputs":[{"output_type":"stream","text":"['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V26', 'V27', 'V28']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = credit[cols]\n\ny = credit['Class'] # selecting the target variable\n\nX.shape","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"(284807, 27)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# computing the class weight\n\nval_count = credit['Class'].value_counts()\nweights = dict(1 / val_count)\nweights","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"{0: 3.51722561243691e-06, 1: 0.0020325203252032522}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adminstrative cost\nadmin_cost = 2.5","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining a function to calculate cost savings\ndef cost_saving(ytrue, ypred, amount):\n    fp = np.sum((ytrue == 0) & (ypred == 1))\n    cost = np.sum(fp*admin_cost) + np.sum((amount[(ytrue == 1) & (ypred == 0)]))\n    max_cost = np.sum((amount[(ytrue == 1)]))\n    savings = 1 - (cost/max_cost)\n    \n    return savings","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=1)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining a function to calculate cost saving per fold (splits) of our cv\ndef cost_saving_per_split(scores, x, y, cv_object):\n    results = []\n    for i, (_, test_ind) in zip(range(cv_object.n_splits), cv_object.split(x, y)):\n        ypred = scores['estimator'][i].predict(x[test_ind])\n        ytrue = y[test_ind]\n        amount = credit['Amount'].values[test_ind]\n        results.append(cost_saving(ytrue, ypred, amount))\n        \n    return results","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining a function to return a dataframe of metrics results for each fold in our cv\ndef get_metric_scores(scores, x, y=y, cv_object=cv):\n    ind = ['split_'+str(n) for n in range(1, cv_object.n_splits+1)]\n    \n    scores_credit = pd.DataFrame(index=ind)\n    \n    scores_credit['f1_score'] = scores['test_f1']\n    scores_credit['auc_pr'] = scores['test_average_precision']\n    scores_credit['cost_savings'] = cost_saving_per_split(scores, x, y, cv_object)\n\n    return scores_credit","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fraud sensitive model"},{"metadata":{},"cell_type":"markdown","source":"**Using the default loss fucntion 'hinge'**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fraud_sensitive_model = SGDClassifier(class_weight=weights)\nfraud_sensitive_scaler = StandardScaler()\n\nfraud_sensitive_pipe = Pipeline([('scaler', fraud_sensitive_scaler), ('model', fraud_sensitive_model)])\nfraud_sensitive_scores = cross_validate(fraud_sensitive_pipe, np.array(X), y, \n                                        scoring=['f1', 'average_precision'], \n                                        cv=cv, n_jobs=4, return_estimator=True,error_score='raise')","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fraud_sensitive_results = get_metric_scores(fraud_sensitive_scores, np.array(X))\nfraud_sensitive_results","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"         f1_score    auc_pr  cost_savings\nsplit_1  0.295552  0.681210      0.681467\nsplit_2  0.230366  0.807092      0.696131\nsplit_3  0.279793  0.781729      0.726355\nsplit_4  0.184071  0.738705      0.585969","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>f1_score</th>\n      <th>auc_pr</th>\n      <th>cost_savings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>split_1</th>\n      <td>0.295552</td>\n      <td>0.681210</td>\n      <td>0.681467</td>\n    </tr>\n    <tr>\n      <th>split_2</th>\n      <td>0.230366</td>\n      <td>0.807092</td>\n      <td>0.696131</td>\n    </tr>\n    <tr>\n      <th>split_3</th>\n      <td>0.279793</td>\n      <td>0.781729</td>\n      <td>0.726355</td>\n    </tr>\n    <tr>\n      <th>split_4</th>\n      <td>0.184071</td>\n      <td>0.738705</td>\n      <td>0.585969</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"fraud_sensitive_results.mean()","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"f1_score        0.247446\nauc_pr          0.752184\ncost_savings    0.672481\ndtype: float64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Fraud Sensitive model using 'log' loss function"},{"metadata":{"trusted":true},"cell_type":"code","source":"fraud_sensitive_model = SGDClassifier(class_weight=weights, loss = 'log')\nfraud_sensitive_scaler = StandardScaler()\n\nfraud_sensitive_pipe = Pipeline([('scaler', fraud_sensitive_scaler), ('model', fraud_sensitive_model)])\nfraud_sensitive_scores = cross_validate(fraud_sensitive_pipe, np.array(X), y, \n                                        scoring=['f1', 'average_precision'], \n                                        cv=cv, n_jobs=4, return_estimator=True,error_score='raise')","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fraud_sensitive_results = get_metric_scores(fraud_sensitive_scores, np.array(X))\nfraud_sensitive_results","execution_count":43,"outputs":[{"output_type":"execute_result","execution_count":43,"data":{"text/plain":"         f1_score    auc_pr  cost_savings\nsplit_1  0.126946  0.679635      0.585948\nsplit_2  0.118009  0.805008      0.548138\nsplit_3  0.139225  0.781807      0.672897\nsplit_4  0.130061  0.742267      0.550660","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>f1_score</th>\n      <th>auc_pr</th>\n      <th>cost_savings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>split_1</th>\n      <td>0.126946</td>\n      <td>0.679635</td>\n      <td>0.585948</td>\n    </tr>\n    <tr>\n      <th>split_2</th>\n      <td>0.118009</td>\n      <td>0.805008</td>\n      <td>0.548138</td>\n    </tr>\n    <tr>\n      <th>split_3</th>\n      <td>0.139225</td>\n      <td>0.781807</td>\n      <td>0.672897</td>\n    </tr>\n    <tr>\n      <th>split_4</th>\n      <td>0.130061</td>\n      <td>0.742267</td>\n      <td>0.550660</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"fraud_sensitive_results.mean()","execution_count":44,"outputs":[{"output_type":"execute_result","execution_count":44,"data":{"text/plain":"f1_score        0.128560\nauc_pr          0.752179\ncost_savings    0.589411\ndtype: float64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**Using 'hinge' as loss function performs better than using 'log'**"},{"metadata":{},"cell_type":"markdown","source":"### Cost sensitive model"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_weights = np.array([credit['Amount'][ind] if fraud else admin_cost for ind, fraud in enumerate(y)])","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler2 = StandardScaler()\ncost_sensitive_model = SGDClassifier(loss = 'log')\n\ncost_sensitive_pipe = Pipeline([('scaler', scaler2), ('model', cost_sensitive_model)])\ncost_sensitive_scores = cross_validate(cost_sensitive_model, np.array(X), y, \n                                       scoring=['f1', 'average_precision'], \n                                       cv=cv, n_jobs=4, return_estimator=True, \n                                       fit_params={'sample_weight': sample_weights})","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using 'log' as loss function\ncost_sensitive_results = get_metric_scores(cost_sensitive_scores, np.array(X))\ncost_sensitive_results","execution_count":39,"outputs":[{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"         f1_score    auc_pr  cost_savings\nsplit_1  0.394422  0.559518      0.701118\nsplit_2  0.457143  0.599449      0.693992\nsplit_3  0.464037  0.600435      0.742666\nsplit_4  0.411290  0.668705      0.724050","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>f1_score</th>\n      <th>auc_pr</th>\n      <th>cost_savings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>split_1</th>\n      <td>0.394422</td>\n      <td>0.559518</td>\n      <td>0.701118</td>\n    </tr>\n    <tr>\n      <th>split_2</th>\n      <td>0.457143</td>\n      <td>0.599449</td>\n      <td>0.693992</td>\n    </tr>\n    <tr>\n      <th>split_3</th>\n      <td>0.464037</td>\n      <td>0.600435</td>\n      <td>0.742666</td>\n    </tr>\n    <tr>\n      <th>split_4</th>\n      <td>0.411290</td>\n      <td>0.668705</td>\n      <td>0.724050</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using 'hinge' as loss function\ncost_sensitive_results = get_metric_scores(cost_sensitive_scores, np.array(X))\ncost_sensitive_results","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"         f1_score    auc_pr  cost_savings\nsplit_1  0.378987  0.622352      0.701797\nsplit_2  0.408560  0.605560      0.699225\nsplit_3  0.459770  0.662554      0.741973\nsplit_4  0.420168  0.542667      0.678335","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>f1_score</th>\n      <th>auc_pr</th>\n      <th>cost_savings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>split_1</th>\n      <td>0.378987</td>\n      <td>0.622352</td>\n      <td>0.701797</td>\n    </tr>\n    <tr>\n      <th>split_2</th>\n      <td>0.408560</td>\n      <td>0.605560</td>\n      <td>0.699225</td>\n    </tr>\n    <tr>\n      <th>split_3</th>\n      <td>0.459770</td>\n      <td>0.662554</td>\n      <td>0.741973</td>\n    </tr>\n    <tr>\n      <th>split_4</th>\n      <td>0.420168</td>\n      <td>0.542667</td>\n      <td>0.678335</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cost_sensitive_results.mean() #Using 'log' as loss function","execution_count":40,"outputs":[{"output_type":"execute_result","execution_count":40,"data":{"text/plain":"f1_score        0.431723\nauc_pr          0.607027\ncost_savings    0.715457\ndtype: float64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cost_sensitive_results.mean() #using 'hing' as loss function","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"f1_score        0.416871\nauc_pr          0.608283\ncost_savings    0.705332\ndtype: float64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**Using 'log' as loss function performs better than using 'hinge'**"},{"metadata":{},"cell_type":"markdown","source":"### Bayes Minimum Risk (BMR)"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler3 = StandardScaler()\nbmr_model = SGDClassifier(loss = 'log') #Using 'log' as loss function\n\nbmr_pipe = Pipeline([('scaler', scaler3), ('model', bmr_model)])\n\nbmr_scores = cross_validate(bmr_pipe, np.array(X), y, cv=cv, n_jobs=4, return_estimator=True, \\\n                            error_score='raise')","execution_count":33,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**I used 'log' loss function for BMR because the default one 'hinge' doesnt support predict probabilities**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining a function to predict based on the predicting that will minimize the expected cost.\ndef bmr_predict(model, x, trans_cost):\n    prob = model.predict_proba(x)[:, 1]\n        \n    expected_cost_0 = prob * trans_cost\n    expected_cost_1 = (1-prob) * admin_cost\n        \n    pred = (expected_cost_1 < expected_cost_0).astype(int)\n    return pred","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_bmr_metric_scores(scores, x, y=y, cv_object=cv):\n    ind = ['split_'+str(n) for n in range(1, cv_object.n_splits+1)]\n    scores_df = pd.DataFrame(index=ind)\n\n    f1_results = []\n    cs_results = []\n    \n    for i, (_, test_ind) in zip(range(cv_object.n_splits), cv_object.split(x, y)):\n        amount = df['Amount'].values[test_ind]\n        \n        ypred = bmr_predict(scores['estimator'][i], x[test_ind], amount)\n        ytrue = y[test_ind]\n                \n        f1_results.append(f1_score(ytrue, ypred))\n        cs_results.append(cost_saving(ytrue, ypred, amount))\n        \n    scores_df['f1_score'] = f1_results\n    #scores_df['auc_pr'] = scores['test_average_precision']\n    scores_df['cost_savings'] = cs_results\n\n    return scores_df","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nbmr_results = get_bmr_metric_scores(bmr_scores, np.array(X))\nbmr_results","execution_count":36,"outputs":[{"output_type":"execute_result","execution_count":36,"data":{"text/plain":"         f1_score  cost_savings\nsplit_1  0.606061      0.377942\nsplit_2  0.673367      0.410996\nsplit_3  0.689655      0.486742\nsplit_4  0.625000      0.335728","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>f1_score</th>\n      <th>cost_savings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>split_1</th>\n      <td>0.606061</td>\n      <td>0.377942</td>\n    </tr>\n    <tr>\n      <th>split_2</th>\n      <td>0.673367</td>\n      <td>0.410996</td>\n    </tr>\n    <tr>\n      <th>split_3</th>\n      <td>0.689655</td>\n      <td>0.486742</td>\n    </tr>\n    <tr>\n      <th>split_4</th>\n      <td>0.625000</td>\n      <td>0.335728</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"bmr_results.mean()","execution_count":41,"outputs":[{"output_type":"execute_result","execution_count":41,"data":{"text/plain":"f1_score        0.648521\ncost_savings    0.402852\ndtype: float64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"****Surprisingly BMR has a higher F1-score and lower  cost savings****"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}