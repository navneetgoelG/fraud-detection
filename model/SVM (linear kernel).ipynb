{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.ipynb_checkpoints',\n",
       " '.txt',\n",
       " 'baseline-model.ipynb',\n",
       " 'data',\n",
       " 'EDA_and_preprocessing',\n",
       " 'elliptic_envelope',\n",
       " 'GradientBoosting.ipynb',\n",
       " 'images',\n",
       " 'model',\n",
       " 'model2',\n",
       " 'one_class_svm',\n",
       " 'pipeline',\n",
       " 'README.md']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve,average_precision_score,confusion_matrix,classification_report\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score,roc_curve,roc_auc_score,f1_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split,cross_validate\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LinearSVC in module sklearn.svm._classes:\n",
      "\n",
      "class LinearSVC(sklearn.base.BaseEstimator, sklearn.linear_model._base.LinearClassifierMixin, sklearn.linear_model._base.SparseCoefMixin)\n",
      " |  LinearSVC(penalty='l2', loss='squared_hinge', *, dual=True, tol=0.0001, C=1.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1, class_weight=None, verbose=0, random_state=None, max_iter=1000)\n",
      " |  \n",
      " |  Linear Support Vector Classification.\n",
      " |  \n",
      " |  Similar to SVC with parameter kernel='linear', but implemented in terms of\n",
      " |  liblinear rather than libsvm, so it has more flexibility in the choice of\n",
      " |  penalties and loss functions and should scale better to large numbers of\n",
      " |  samples.\n",
      " |  \n",
      " |  This class supports both dense and sparse input and the multiclass support\n",
      " |  is handled according to a one-vs-the-rest scheme.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <svm_classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  penalty : {'l1', 'l2'}, default='l2'\n",
      " |      Specifies the norm used in the penalization. The 'l2'\n",
      " |      penalty is the standard used in SVC. The 'l1' leads to ``coef_``\n",
      " |      vectors that are sparse.\n",
      " |  \n",
      " |  loss : {'hinge', 'squared_hinge'}, default='squared_hinge'\n",
      " |      Specifies the loss function. 'hinge' is the standard SVM loss\n",
      " |      (used e.g. by the SVC class) while 'squared_hinge' is the\n",
      " |      square of the hinge loss.\n",
      " |  \n",
      " |  dual : bool, default=True\n",
      " |      Select the algorithm to either solve the dual or primal\n",
      " |      optimization problem. Prefer dual=False when n_samples > n_features.\n",
      " |  \n",
      " |  tol : float, default=1e-4\n",
      " |      Tolerance for stopping criteria.\n",
      " |  \n",
      " |  C : float, default=1.0\n",
      " |      Regularization parameter. The strength of the regularization is\n",
      " |      inversely proportional to C. Must be strictly positive.\n",
      " |  \n",
      " |  multi_class : {'ovr', 'crammer_singer'}, default='ovr'\n",
      " |      Determines the multi-class strategy if `y` contains more than\n",
      " |      two classes.\n",
      " |      ``\"ovr\"`` trains n_classes one-vs-rest classifiers, while\n",
      " |      ``\"crammer_singer\"`` optimizes a joint objective over all classes.\n",
      " |      While `crammer_singer` is interesting from a theoretical perspective\n",
      " |      as it is consistent, it is seldom used in practice as it rarely leads\n",
      " |      to better accuracy and is more expensive to compute.\n",
      " |      If ``\"crammer_singer\"`` is chosen, the options loss, penalty and dual\n",
      " |      will be ignored.\n",
      " |  \n",
      " |  fit_intercept : bool, default=True\n",
      " |      Whether to calculate the intercept for this model. If set\n",
      " |      to false, no intercept will be used in calculations\n",
      " |      (i.e. data is expected to be already centered).\n",
      " |  \n",
      " |  intercept_scaling : float, default=1\n",
      " |      When self.fit_intercept is True, instance vector x becomes\n",
      " |      ``[x, self.intercept_scaling]``,\n",
      " |      i.e. a \"synthetic\" feature with constant value equals to\n",
      " |      intercept_scaling is appended to the instance vector.\n",
      " |      The intercept becomes intercept_scaling * synthetic feature weight\n",
      " |      Note! the synthetic feature weight is subject to l1/l2 regularization\n",
      " |      as all other features.\n",
      " |      To lessen the effect of regularization on synthetic feature weight\n",
      " |      (and therefore on the intercept) intercept_scaling has to be increased.\n",
      " |  \n",
      " |  class_weight : dict or 'balanced', default=None\n",
      " |      Set the parameter C of class i to ``class_weight[i]*C`` for\n",
      " |      SVC. If not given, all classes are supposed to have\n",
      " |      weight one.\n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Enable verbose output. Note that this setting takes advantage of a\n",
      " |      per-process runtime setting in liblinear that, if enabled, may not work\n",
      " |      properly in a multithreaded context.\n",
      " |  \n",
      " |  random_state : int or RandomState instance, default=None\n",
      " |      Controls the pseudo random number generation for shuffling the data for\n",
      " |      the dual coordinate descent (if ``dual=True``). When ``dual=False`` the\n",
      " |      underlying implementation of :class:`LinearSVC` is not random and\n",
      " |      ``random_state`` has no effect on the results.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  max_iter : int, default=1000\n",
      " |      The maximum number of iterations to be run.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : ndarray of shape (1, n_features) if n_classes == 2             else (n_classes, n_features)\n",
      " |      Weights assigned to the features (coefficients in the primal\n",
      " |      problem). This is only available in the case of a linear kernel.\n",
      " |  \n",
      " |      ``coef_`` is a readonly property derived from ``raw_coef_`` that\n",
      " |      follows the internal memory layout of liblinear.\n",
      " |  \n",
      " |  intercept_ : ndarray of shape (1,) if n_classes == 2 else (n_classes,)\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      The unique classes labels.\n",
      " |  \n",
      " |  n_iter_ : int\n",
      " |      Maximum number of iterations run across all classes.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  SVC\n",
      " |      Implementation of Support Vector Machine classifier using libsvm:\n",
      " |      the kernel can be non-linear but its SMO algorithm does not\n",
      " |      scale to large number of samples as LinearSVC does.\n",
      " |  \n",
      " |      Furthermore SVC multi-class mode is implemented using one\n",
      " |      vs one scheme while LinearSVC uses one vs the rest. It is\n",
      " |      possible to implement one vs the rest with SVC by using the\n",
      " |      :class:`sklearn.multiclass.OneVsRestClassifier` wrapper.\n",
      " |  \n",
      " |      Finally SVC can fit dense data without memory copy if the input\n",
      " |      is C-contiguous. Sparse data will still incur memory copy though.\n",
      " |  \n",
      " |  sklearn.linear_model.SGDClassifier\n",
      " |      SGDClassifier can optimize the same cost function as LinearSVC\n",
      " |      by adjusting the penalty and loss parameters. In addition it requires\n",
      " |      less memory, allows incremental (online) learning, and implements\n",
      " |      various loss functions and regularization regimes.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The underlying C implementation uses a random number generator to\n",
      " |  select features when fitting the model. It is thus not uncommon\n",
      " |  to have slightly different results for the same input data. If\n",
      " |  that happens, try with a smaller ``tol`` parameter.\n",
      " |  \n",
      " |  The underlying implementation, liblinear, uses a sparse internal\n",
      " |  representation for the data that will incur a memory copy.\n",
      " |  \n",
      " |  Predict output may not match that of standalone liblinear in certain\n",
      " |  cases. See :ref:`differences from liblinear <liblinear_differences>`\n",
      " |  in the narrative documentation.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  `LIBLINEAR: A Library for Large Linear Classification\n",
      " |  <https://www.csie.ntu.edu.tw/~cjlin/liblinear/>`__\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.svm import LinearSVC\n",
      " |  >>> from sklearn.pipeline import make_pipeline\n",
      " |  >>> from sklearn.preprocessing import StandardScaler\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>> X, y = make_classification(n_features=4, random_state=0)\n",
      " |  >>> clf = make_pipeline(StandardScaler(),\n",
      " |  ...                     LinearSVC(random_state=0, tol=1e-5))\n",
      " |  >>> clf.fit(X, y)\n",
      " |  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      " |                  ('linearsvc', LinearSVC(random_state=0, tol=1e-05))])\n",
      " |  \n",
      " |  >>> print(clf.named_steps['linearsvc'].coef_)\n",
      " |  [[0.141...   0.526... 0.679... 0.493...]]\n",
      " |  \n",
      " |  >>> print(clf.named_steps['linearsvc'].intercept_)\n",
      " |  [0.1693...]\n",
      " |  >>> print(clf.predict([[0, 0, 0, 0]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LinearSVC\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.linear_model._base.LinearClassifierMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.linear_model._base.SparseCoefMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, penalty='l2', loss='squared_hinge', *, dual=True, tol=0.0001, C=1.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1, class_weight=None, verbose=0, random_state=None, max_iter=1000)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training vector, where n_samples in the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target vector relative to X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Array of weights that are assigned to individual\n",
      " |          samples. If not provided,\n",
      " |          then each sample is given unit weight.\n",
      " |      \n",
      " |          .. versionadded:: 0.18\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          An instance of the estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.LinearClassifierMixin:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Predict confidence scores for samples.\n",
      " |      \n",
      " |      The confidence score for a sample is the signed distance of that\n",
      " |      sample to the hyperplane.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)\n",
      " |          Confidence scores per (sample, class) combination. In the binary\n",
      " |          case, confidence score for self.classes_[1] where >0 means this\n",
      " |          class would be predicted.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class labels for samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape [n_samples]\n",
      " |          Predicted class label per sample.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.SparseCoefMixin:\n",
      " |  \n",
      " |  densify(self)\n",
      " |      Convert coefficient matrix to dense array format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      " |      default format of ``coef_`` and is required for fitting, so calling\n",
      " |      this method is only required on models that have previously been\n",
      " |      sparsified; otherwise, it is a no-op.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  sparsify(self)\n",
      " |      Convert coefficient matrix to sparse format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      " |      L1-regularized models can be much more memory- and storage-efficient\n",
      " |      than the usual numpy.ndarray representation.\n",
      " |      \n",
      " |      The ``intercept_`` member is not converted.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |          Fitted estimator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      " |      this may actually *increase* memory usage, so use this method with\n",
      " |      care. A rule of thumb is that the number of zero elements, which can\n",
      " |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      " |      to provide significant benefits.\n",
      " |      \n",
      " |      After calling this method, further fitting with the partial_fit\n",
      " |      method (if any) will not work until you call densify.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(svm.LinearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/creditcard.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time     -0.012323\n",
       "V1       -0.101347\n",
       "V2        0.091289\n",
       "V3       -0.192961\n",
       "V4        0.133447\n",
       "V5       -0.094974\n",
       "V6       -0.043643\n",
       "V7       -0.187257\n",
       "V8        0.019875\n",
       "V9       -0.097733\n",
       "V10      -0.216883\n",
       "V11       0.154876\n",
       "V12      -0.260593\n",
       "V13      -0.004570\n",
       "V14      -0.302544\n",
       "V15      -0.004223\n",
       "V16      -0.196539\n",
       "V17      -0.326481\n",
       "V18      -0.111485\n",
       "V19       0.034783\n",
       "V20       0.020090\n",
       "V21       0.040413\n",
       "V22       0.000805\n",
       "V23      -0.002685\n",
       "V24      -0.007221\n",
       "V25       0.003308\n",
       "V26       0.004455\n",
       "V27       0.017580\n",
       "V28       0.009536\n",
       "Amount    0.005632\n",
       "Class     1.000000\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr().Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the most important features already listed in the baseline model \n",
    "\n",
    "df = data[['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', \n",
    "             'V11','V12','V13','V14','V16','V17','V21','V23','V27']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163152.0    36\n",
       "64947.0     26\n",
       "68780.0     25\n",
       "3767.0      21\n",
       "3770.0      20\n",
       "            ..\n",
       "2088.0       1\n",
       "64100.0      1\n",
       "42068.0      1\n",
       "119630.0     1\n",
       "140344.0     1\n",
       "Name: Time, Length: 124592, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to know the frequency of different time recorded\n",
    "data.Time.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163152.0    36\n",
       "64947.0     26\n",
       "68780.0     25\n",
       "3767.0      21\n",
       "3770.0      20\n",
       "            ..\n",
       "154306.0     1\n",
       "5380.0       1\n",
       "105479.0     1\n",
       "52741.0      1\n",
       "90714.0      1\n",
       "Name: Time, Length: 124479, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['Class']==0, 'Time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68207.0     6\n",
       "94362.0     4\n",
       "85285.0     4\n",
       "93860.0     4\n",
       "84204.0     4\n",
       "           ..\n",
       "158638.0    1\n",
       "125658.0    1\n",
       "28692.0     1\n",
       "15817.0     1\n",
       "406.0       1\n",
       "Name: Time, Length: 468, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['Class']==1, 'Time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.figure(figsize=(20,20))\n",
    "plt.plot(data.loc[data['Class']==0, 'Time'], 'o',color= 'b')\n",
    "plt.plot(data.loc[data['Class']==1, 'Time'], 'v', color= 'g' )\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows the spread of the fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 19 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   V1      284807 non-null  float64\n",
      " 1   V2      284807 non-null  float64\n",
      " 2   V3      284807 non-null  float64\n",
      " 3   V4      284807 non-null  float64\n",
      " 4   V5      284807 non-null  float64\n",
      " 5   V6      284807 non-null  float64\n",
      " 6   V7      284807 non-null  float64\n",
      " 7   V8      284807 non-null  float64\n",
      " 8   V9      284807 non-null  float64\n",
      " 9   V10     284807 non-null  float64\n",
      " 10  V11     284807 non-null  float64\n",
      " 11  V12     284807 non-null  float64\n",
      " 12  V13     284807 non-null  float64\n",
      " 13  V14     284807 non-null  float64\n",
      " 14  V16     284807 non-null  float64\n",
      " 15  V17     284807 non-null  float64\n",
      " 16  V21     284807 non-null  float64\n",
      " 17  V23     284807 non-null  float64\n",
      " 18  V27     284807 non-null  float64\n",
      "dtypes: float64(19)\n",
      "memory usage: 41.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 3.51722561243691e-06, 1: 0.0020325203252032522}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# working with raw data lets check how it will fare\n",
    "\n",
    "# computing the class weight\n",
    "\n",
    "val_count = data['Class'].value_counts()\n",
    "weights = dict(1 / val_count)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adminstrative cost\n",
    "admin_cost = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to calculate cost savings\n",
    "def cost_saving(ytrue, ypred, amount):\n",
    "    fp = np.sum((ytrue == 0) & (ypred == 1))\n",
    "    cost = np.sum(fp*admin_cost) + np.sum((amount[(ytrue == 1) & (ypred == 0)]))\n",
    "    max_cost = np.sum((amount[(ytrue == 1)]))\n",
    "    savings = 1 - (cost/max_cost)\n",
    "    \n",
    "    return savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to calculate cost saving per fold (splits) of our cv\n",
    "def cost_saving_per_split(scores, x, y, cv_object):\n",
    "    results = []\n",
    "    for i, (_, test_ind) in zip(range(cv_object.n_splits), cv_object.split(x, y)):\n",
    "        ypred = scores['estimator'][i].predict(x[test_ind])\n",
    "        ytrue = y[test_ind]\n",
    "        amount = data['Amount'].values[test_ind]\n",
    "        results.append(cost_saving(ytrue, ypred, amount))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to return a dataframe of metrics results for each fold in our cv\n",
    "def get_metric_scores(scores, x, y, cv_object=cv):\n",
    "    ind = ['split_'+str(n) for n in range(1, cv_object.n_splits+1)]\n",
    "    \n",
    "    scores_credit = pd.DataFrame(index=ind)\n",
    "    \n",
    "    scores_credit['f1_score'] = scores['test_f1']\n",
    "    scores_credit['auc_pr'] = scores['test_average_precision']\n",
    "    scores_credit['cost_savings'] = cost_saving_per_split(scores, x, y, cv_object)\n",
    "\n",
    "    return scores_credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fraud Sensitive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.LinearSVC()\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "MMscaled_ = minmax.fit_transform(df)\n",
    "y= data.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_sensitive_scores = cross_validate(model, MMscaled_, y, \n",
    "                                        scoring=['f1', 'average_precision'], \n",
    "                                        cv=cv, n_jobs=4, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_pr</th>\n",
       "      <th>cost_savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split_1</th>\n",
       "      <td>0.769912</td>\n",
       "      <td>0.629538</td>\n",
       "      <td>0.916541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_2</th>\n",
       "      <td>0.757764</td>\n",
       "      <td>0.861236</td>\n",
       "      <td>0.555311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_3</th>\n",
       "      <td>0.573427</td>\n",
       "      <td>0.723726</td>\n",
       "      <td>0.407193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_4</th>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.871641</td>\n",
       "      <td>0.298538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_5</th>\n",
       "      <td>0.579710</td>\n",
       "      <td>0.817160</td>\n",
       "      <td>0.323421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1_score    auc_pr  cost_savings\n",
       "split_1  0.769912  0.629538      0.916541\n",
       "split_2  0.757764  0.861236      0.555311\n",
       "split_3  0.573427  0.723726      0.407193\n",
       "split_4  0.775000  0.871641      0.298538\n",
       "split_5  0.579710  0.817160      0.323421"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_sensitive_results = get_metric_scores(fraud_sensitive_scores, MMscaled_,y)\n",
    "fraud_sensitive_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1_score        0.691162\n",
       "auc_pr          0.780660\n",
       "cost_savings    0.500201\n",
       "dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_sensitive_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Sensitive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = np.array([data['Amount'][ind] if fraud else admin_cost for ind, fraud in enumerate(y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_sensitive_model = svm.LinearSVC()\n",
    "cost_sensitive_scores = cross_validate(cost_sensitive_model, MMscaled_, y, \n",
    "                                       scoring=['f1', 'average_precision'], \n",
    "                                       cv=cv, n_jobs=4, return_estimator=True, \n",
    "                                       fit_params={'sample_weight': sample_weights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_pr</th>\n",
       "      <th>cost_savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split_1</th>\n",
       "      <td>0.759825</td>\n",
       "      <td>0.649213</td>\n",
       "      <td>0.915714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_2</th>\n",
       "      <td>0.877005</td>\n",
       "      <td>0.855794</td>\n",
       "      <td>0.794453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_3</th>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.693777</td>\n",
       "      <td>0.770361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_4</th>\n",
       "      <td>0.882979</td>\n",
       "      <td>0.865764</td>\n",
       "      <td>0.558809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_5</th>\n",
       "      <td>0.817680</td>\n",
       "      <td>0.785174</td>\n",
       "      <td>0.788435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1_score    auc_pr  cost_savings\n",
       "split_1  0.759825  0.649213      0.915714\n",
       "split_2  0.877005  0.855794      0.794453\n",
       "split_3  0.720430  0.693777      0.770361\n",
       "split_4  0.882979  0.865764      0.558809\n",
       "split_5  0.817680  0.785174      0.788435"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_sensitive_results = get_metric_scores(cost_sensitive_scores, MMscaled_, y)\n",
    "cost_sensitive_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1_score        0.811584\n",
       "auc_pr          0.769944\n",
       "cost_savings    0.765554\n",
       "dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_sensitive_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score: 0.9043899061309327\n",
      "f-score: 0.12713178294573643\n",
      "roc_auc_score: 0.9382277481744622\n",
      "f-score: 0.19686800894854586\n",
      "roc_auc_score: 0.9094356575614789\n",
      "f-score: 0.09341586944288127\n",
      "roc_auc_score: 0.9497068141221633\n",
      "f-score: 0.09853817000541419\n",
      "roc_auc_score: 0.9179054419017136\n",
      "f-score: 0.1204301075268817\n",
      "Wall time: 2min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "smote = SMOTE()\n",
    "\n",
    "for train_idx, test_idx, in cv.split(MMscaled_, y):\n",
    "    X_train, y_train = MMscaled_[train_idx], y[train_idx]\n",
    "    X_test, y_test = MMscaled_[test_idx], y[test_idx]\n",
    "    X_train_oversampled, y_train_oversampled = smote.fit_sample(X_train, y_train)\n",
    "    smote_gradient_model = svm.LinearSVC()\n",
    "    smote_gradient_model.fit(X_train_oversampled, y_train_oversampled )  \n",
    "    pred = smote_gradient_model.predict(X_test)\n",
    "    print(f'roc_auc_score: {roc_auc_score(y_test, pred)}')\n",
    "    print(f'f-score: {f1_score(y_test, pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pipelining with standardscaler plus LinearSVC, and prescaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a pipeline \n",
    "clf = make_pipeline(MinMaxScaler(),\n",
    "                   svm.LinearSVC(tol=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "F1_scores [0.7699115044247787, 0.7499999999999999, 0.5774647887323944, 0.782608695652174, 0.5797101449275363]\n",
      "roc_auc_scores [0.9390422168326957, 0.803021509966272, 0.7091572942772945, 0.8214285714285714, 0.7040816326530612]\n",
      "Wall time: 22.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f1_pipeline_scores =[]\n",
    "auc_pipeline_scores = []\n",
    "\n",
    "for train, test in cv.split(MMscaled_, y):\n",
    "#     df.reset_index(inplace=True)\n",
    "    print(0)\n",
    "    Xtr, ytr = MMscaled_[train], y[train]\n",
    "    print(1)\n",
    "    xte, yte = MMscaled_[test], y[test]\n",
    "    print(2)\n",
    "    clf.fit(Xtr,ytr)\n",
    "    print(3)\n",
    "    y_pred = clf.predict(xte)\n",
    "    f1_pipeline_scores.append(f1_score(yte,y_pred))\n",
    "    auc_pipeline_scores.append(roc_auc_score(yte,y_pred))\n",
    "\n",
    "print('F1_scores', f1_pipeline_scores)\n",
    "print('roc_auc_scores', auc_pipeline_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Very good f1 scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V1    -0.240440\n",
       "V2     0.530483\n",
       "V3     0.702510\n",
       "V4     0.689799\n",
       "V5    -0.377961\n",
       "V6     0.623708\n",
       "V7    -0.686180\n",
       "V8     0.679145\n",
       "V9     0.392087\n",
       "V10   -0.399126\n",
       "V11   -1.933849\n",
       "V12   -0.962886\n",
       "V13   -1.042082\n",
       "V14    0.449624\n",
       "V16   -0.608577\n",
       "V17    0.509928\n",
       "V21    0.265245\n",
       "V23   -0.163298\n",
       "V27    0.108821\n",
       "Name: 284805, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[284805]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fraud Sensistive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_sensitive_model = svm.LinearSVC()\n",
    "\n",
    "Scale = StandardScaler()\n",
    "SSscaled = Scale.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_sensitive_scores = cross_validate(fraud_sensitive_model, SSscaled, y, \n",
    "                                        scoring=['f1', 'average_precision'], \n",
    "                                        cv=cv, n_jobs=4, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_pr</th>\n",
       "      <th>cost_savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split_1</th>\n",
       "      <td>0.734884</td>\n",
       "      <td>0.607545</td>\n",
       "      <td>0.829158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_2</th>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.857691</td>\n",
       "      <td>0.607148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_3</th>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.711922</td>\n",
       "      <td>0.392886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_4</th>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.872608</td>\n",
       "      <td>0.217257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_5</th>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.816049</td>\n",
       "      <td>0.538049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1_score    auc_pr  cost_savings\n",
       "split_1  0.734884  0.607545      0.829158\n",
       "split_2  0.837209  0.857691      0.607148\n",
       "split_3  0.557143  0.711922      0.392886\n",
       "split_4  0.629371  0.872608      0.217257\n",
       "split_5  0.710526  0.816049      0.538049"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_sensitive_results = get_metric_scores(fraud_sensitive_scores, SSscaled,y)\n",
    "fraud_sensitive_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1_score        0.693827\n",
       "auc_pr          0.773163\n",
       "cost_savings    0.516899\n",
       "dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_sensitive_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Sensitive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = np.array([data['Amount'][ind] if fraud else admin_cost for ind, fraud in enumerate(y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_sensitive_model = svm.LinearSVC()\n",
    "cost_sensitive_scores = cross_validate(cost_sensitive_model, SSscaled, y, \n",
    "                                       scoring=['f1', 'average_precision'], \n",
    "                                       cv=cv, n_jobs=4, return_estimator=True, \n",
    "                                       fit_params={'sample_weight': sample_weights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_pr</th>\n",
       "      <th>cost_savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split_1</th>\n",
       "      <td>0.765217</td>\n",
       "      <td>0.671882</td>\n",
       "      <td>0.915789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_2</th>\n",
       "      <td>0.850575</td>\n",
       "      <td>0.854958</td>\n",
       "      <td>0.718693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_3</th>\n",
       "      <td>0.735135</td>\n",
       "      <td>0.694818</td>\n",
       "      <td>0.789448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_4</th>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.862394</td>\n",
       "      <td>0.559582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_5</th>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.754645</td>\n",
       "      <td>0.687040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1_score    auc_pr  cost_savings\n",
       "split_1  0.765217  0.671882      0.915789\n",
       "split_2  0.850575  0.854958      0.718693\n",
       "split_3  0.735135  0.694818      0.789448\n",
       "split_4  0.902174  0.862394      0.559582\n",
       "split_5  0.762500  0.754645      0.687040"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_sensitive_results = get_metric_scores(cost_sensitive_scores, SSscaled,y)\n",
    "cost_sensitive_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1_score        0.803120\n",
       "auc_pr          0.767739\n",
       "cost_savings    0.734110\n",
       "dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_sensitive_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADELEKE OLADAPO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score: 0.898882161750811\n",
      "f-score: 0.12080536912751678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADELEKE OLADAPO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score: 0.9376737851405034\n",
      "f-score: 0.1839080459770115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADELEKE OLADAPO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score: 0.9149070070671111\n",
      "f-score: 0.0967741935483871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADELEKE OLADAPO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score: 0.9483702683894372\n",
      "f-score: 0.09104552276138068\n",
      "roc_auc_score: 0.9178966488376825\n",
      "f-score: 0.12034383954154727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADELEKE OLADAPO\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE()\n",
    "\n",
    "for train_idx, test_idx, in cv.split(SSscaled, y):\n",
    "    X_train, y_train = SSscaled[train_idx], y[train_idx]\n",
    "    X_test, y_test = SSscaled[test_idx], y[test_idx]\n",
    "    X_train_oversampled, y_train_oversampled = smote.fit_sample(X_train, y_train)\n",
    "    smote_gradient_model = svm.LinearSVC()\n",
    "    smote_gradient_model.fit(X_train_oversampled, y_train_oversampled )  \n",
    "    pred = smote_gradient_model.predict(X_test)\n",
    "    print(f'roc_auc_score: {roc_auc_score(y_test, pred)}')\n",
    "    print(f'f-score: {f1_score(y_test, pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
